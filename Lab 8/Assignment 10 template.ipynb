{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Namazbayev Almas"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "For this assignment you need to:\n",
    "    Prepare the data - stopwords, stemming\n",
    "    Apply both: bag of words and tfIdf\n",
    "    Apply Logistic Regression, SVM, and NaiveBayes for the ready dataset\n",
    "    Compare accuracies for bag of words and tfidf with all the algorithms above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer \n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "The sentiment labels are:\n",
    "\n",
    "0 - negative\n",
    "1 - somewhat negative\n",
    "2 - neutral\n",
    "3 - somewhat positive\n",
    "4 - positive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       A series of escapades demonstrating the adage ...\n",
      "1       A series of escapades demonstrating the adage ...\n",
      "2                                                A series\n",
      "3                                                       A\n",
      "4                                                  series\n",
      "                              ...                        \n",
      "4995                                                veers\n",
      "4996                                from its comic course\n",
      "4997                                     its comic course\n",
      "4998                                         comic course\n",
      "4999                                               course\n",
      "Name: Phrase, Length: 5000, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# nltk.download('stopwords')\n",
    "data = pd.read_csv(\"data.tsv\", delimiter='\t', header=0)\n",
    "data = data[0:5000]\n",
    "X = data[['PhraseId', 'SentenceId', 'Phrase']]\n",
    "y = data['Sentiment']\n",
    "print(data['Phrase'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       series escapades demonstrating adage good goos...\n",
      "1         series escapades demonstrating adage good goose\n",
      "2                                                  series\n",
      "3                                                        \n",
      "4                                                  series\n",
      "                              ...                        \n",
      "4995                                                veers\n",
      "4996                                         comic course\n",
      "4997                                         comic course\n",
      "4998                                         comic course\n",
      "4999                                               course\n",
      "Name: Phrase, Length: 5000, dtype: object\n"
     ]
    }
   ],
   "source": [
    "stopWords = set(stopwords.words('english'))\n",
    "data['Phrase'] = data['Phrase'].apply(lambda x: \" \".join([item for item in (x.lower()).split(\" \") if item not in stopWords]))\n",
    "print(data['Phrase'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       series escapades demonstrating adage good goos...\n",
      "1          series escapades demonstrating adage good goos\n",
      "2                                                    seri\n",
      "3                                                        \n",
      "4                                                    seri\n",
      "                              ...                        \n",
      "4995                                                 veer\n",
      "4996                                          comic cours\n",
      "4997                                          comic cours\n",
      "4998                                          comic cours\n",
      "4999                                                cours\n",
      "Name: Phrase, Length: 5000, dtype: object\n"
     ]
    }
   ],
   "source": [
    "stemming = PorterStemmer()\n",
    "data['Phrase'] = data['Phrase'].apply(lambda x: stemming.stem(x))\n",
    "print(data['Phrase'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bag of words and tfIdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bag of Words: (5000, 2081)\n"
     ]
    }
   ],
   "source": [
    "wordsbag = CountVectorizer()\n",
    "Xwordsbag = wordsbag.fit_transform(data['Phrase'])\n",
    "print(\"Bag of Words:\", Xwordsbag.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Words Vectorizer: (5000, 2081)\n"
     ]
    }
   ],
   "source": [
    "vectorizer = TfidfVectorizer()\n",
    "XtfIdf = vectorizer.fit_transform(data['Phrase'])\n",
    "print(\"Words Vectorizer:\", XtfIdf.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Accuracy for wordsbag."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "xTrain, xTest, yTrain, yTest = train_test_split(Xwordsbag, y,test_size=0.2)\n",
    "trainwordsbag, testwordsbag, labeltrainwordsbag, labeltestwordsbag = train_test_split(xTest, yTest, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression: 62.0%\n"
     ]
    }
   ],
   "source": [
    "clf = LogisticRegression(random_state=0, solver='lbfgs', multi_class='multinomial')\n",
    "clf.fit(trainwordsbag, labeltrainwordsbag)\n",
    "print(\"Logistic Regression: {0}%\".format(accuracy_score(labeltestwordsbag, clf.predict(testwordsbag))*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC: 59.0%\n"
     ]
    }
   ],
   "source": [
    "svcwordsbag = SVC()\n",
    "svcwordsbag.fit(trainwordsbag, labeltrainwordsbag)\n",
    "print(\"SVC: {0}%\".format(accuracy_score(labeltestwordsbag, svcwordsbag.predict(testwordsbag))*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NaiveBayes:64.0%\n"
     ]
    }
   ],
   "source": [
    "classifier = MultinomialNB()\n",
    "classifier.fit(xTrain.todense(), yTrain)\n",
    "predicted = classifier.predict(xTest.todense())\n",
    "print (\"NaiveBayes:{}%\".format(accuracy_score(yTest, predicted)*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Accuracy for vectorizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "xTrain, xTest, yTrain, yTest = train_test_split(XtfIdf, y,test_size=0.2)\n",
    "trainTFIDF, testTFIDF, labeltrainTFIDF, labeltestTFIDF = train_test_split(xTest, yTest, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression: 61.0%\n"
     ]
    }
   ],
   "source": [
    "lg = LogisticRegression(random_state=0, solver='lbfgs', multi_class='multinomial')\n",
    "lg.fit(trainTFIDF, labeltrainTFIDF)\n",
    "print(\"Logistic Regression: {0}%\".format(accuracy_score(labeltestTFIDF, lg.predict(testTFIDF))*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC: 61.0%\n"
     ]
    }
   ],
   "source": [
    "svcvectorizer = SVC()\n",
    "svcvectorizer.fit(trainTFIDF, labeltrainTFIDF)\n",
    "print(\"SVC: {0}%\".format(accuracy_score(labeltestTFIDF, svcvectorizer.predict(testTFIDF))*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NaiveBayes:64.4%\n"
     ]
    }
   ],
   "source": [
    "classifier = MultinomialNB()\n",
    "classifier.fit(xTrain.todense(), yTrain)\n",
    "predicted = classifier.predict(xTest.todense())\n",
    "print (\"NaiveBayes:{}%\".format(accuracy_score(yTest, predicted)*100))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
